# SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION
## 摘要
未来多模态AI系统会在我们未来的生活中无处不在。使得这些系统更具交互性的方法是在现实环境或虚拟环境中将其构建为具身代理。当前的具身代理使用一些基础模型作为块来构建，从而使得其利用基础模型的能力来处理和理解视觉和上下文数据，这种方法对于构建能处理更复杂任务的**ai系统**是十分重要的。比如，一个能理解用户行动，人类表现，环境物体的系统可以指导agent在环境中的响应。为了加速基于agent的多模态智能研究，**我们定义agent ai为一系列可以交互的系统，这些系统可以理解语言输入，视觉模拟等环境数据，而且可以产生有意义的具身行动**。我们通过整合外部知识，多感官输入和人类反馈来改进基于下一个具体动作预测的代理系统。我们认为在真实环境中开发agent ai系统，可以减轻大型基础模型的幻觉及其产生环境不正确输出的倾向。
## 介绍
### 动机
随着LLM和VLM在语言熟练度，上下文记忆，直觉推理，多模态感知等方面的巨大潜力，构建一个能在复杂环境中，对于环境物体，人类反馈，多模态输入能够准确理解和识别的agnet成为可能。ai社区由原来的在各个领域设计对于的算法和模型的时代转变为一个agent可以处理多种复杂任务的时代，ai迎来了新的范式。
### 背景
- 大语言模型在大规模的语料上进行训练后，它的能力不光局限于训练数据，在数学推理，专业问题回答等方面甚至可以达到人类专家的水平。
- 具身AI：在机器人领域，研究人员利用大模型做任务规划，利用大模型的零样本学习能力，将复杂的自然语言指令分解为一个个子任务，并用低级控制器去执行子任务，此外还可以将环境的反馈来提升任务的表现。
- 交互学习：ai agent被设计用来从交互中学习。比如说针对语言任务，起初模型会在大规模文本数据上进行训练，这个过程中会使用深度学习算法。这种训练可以使得模型具备基于训练数据的决策，生成和识别任务。之后，ai可以从与用户的反馈中学习，比如用户纠正ai的输出这一行为可以作为ai学习的依据。还有ai可以观察用户的输入方式和习惯来调整输出，即随着用户交互次数的增加，ai的性能越来越好。

